if (is.na(val)) {
return (NA)
}
val <- gsub("\\$", "", val)
val <- gsub(",", "", val)
if (grepl("-", val)) {
range <- strsplit(val, "-")[[1]]
val <- ((as.double(range[1]) + as.double(range[2])) / 2)
} else {
val <- as.double(val)
}
return(val)
}
# Apply the conversion function to Recommended_Customer_Price
newcpu_df$Recommended_Customer_Price <- sapply(newcpu_df$Recommended_Customer_Price, convert_price_to_num)
# Split Cache column into Cache_Size and Cache_Category
newcpu_df = separate(newcpu_df, Cache, into = c("Cache_Size", "Cache_Category"), sep="B")
# Remove the Cache_Category column
newcpu_df = newcpu_df[, -which(names(newcpu_df) == "Cache_Category")]
# Function to convert Cache_Size features from string to numeric
convert_cache_size_to_num <- function(val) {
if (is.na(val)) return(NA)
if (grepl("M", val)) {
return(as.double(gsub("M", "", val)) * 1024)
} else {
return(as.double(gsub("K", "", val)))
}
}
# Apply the conversion function to Cache_Size
newcpu_df$Cache_Size <- sapply(newcpu_df$Cache_Size, convert_cache_size_to_num)
# Function to convert Max_Memory_Size features from string to numeric
convert_mem_size_to_num <- function(val) {
if (is.na(val)) return(NA)
if (grepl("T", val)) {
res <- (as.double(gsub("TB", "", val)) * 1024)
return(res)
} else {
res <- (as.double(gsub("GB", "", val)))
return(res)
}
}
# Apply the conversion function to Max_Memory_Size
newcpu_df$Max_Memory_Size <- sapply(newcpu_df$Max_Memory_Size, convert_mem_size_to_num)
# Function to convert Max_Memory_Bandwidth from string to numeric
convert_mem_bandwidth_to_num <- function(val) {
if (is.na(val)) return(NA)
if (grepl("G", val)) {
res <- (as.double(gsub("GB/s", "", val)))
return(res)
}
}
# Apply the conversion function to Max_Memory_Bandwidth
newcpu_df$Max_Memory_Bandwidth <- sapply(newcpu_df$Max_Memory_Bandwidth, convert_mem_bandwidth_to_num)
# Statistics on the quantity of missing data in variables
apply(is.na(newcpu_df), 2, sum)
# Statistics on the percentage of missing data in variables
apply(is.na(newcpu_df), 2, mean)
# Filter out rows with missing Processor_Base_Frequency values
newcpu_df <- newcpu_df[complete.cases(newcpu_df$Processor_Base_Frequency), ]
# Filter out rows with missing Cache_Size values
newcpu_df <- newcpu_df[complete.cases(newcpu_df$Cache_Size), ]
# Apply the function to replace missing values with the median for columns with NA ratio >= 5% only
target_columns <- c("Launch_Date", "Recommended_Customer_Price", "nb_of_Threads", "Max_Memory_Size", "Max_Memory_Bandwidth")
newcpu_df[target_columns] <- sapply(newcpu_df[target_columns], replace_na_with_median <- function(x) {
median_val = median(x, na.rm = TRUE)
x[is.na(x)] <- median_val
return (x)
})
# Convert the result back into a DataFrame
newcpu_df <- as.data.frame(newcpu_df)
# Statistics on the quantity of missing data in variables
apply(is.na(newcpu_df), 2, sum)
# Statistics on the percentage of missing data in variables
apply(is.na(newcpu_df), 2, mean)
View(newcpu_df)
# Descriptive statistics
summary(newcpu_df)
# Histogram Revenue of each product
# Summary
nF_summ <- newcpu_df %>%
group_by(Product_Collection) %>%
summarize(
sample_size = n(),
mean = mean(Recommended_Customer_Price, na.rm = TRUE),
sd = sd(Recommended_Customer_Price, na.rm = TRUE),
minimum = min(Recommended_Customer_Price, na.rm = TRUE),
first_quantile = quantile(Recommended_Customer_Price, 0.25, na.rm = TRUE),
median = median(Recommended_Customer_Price, na.rm = TRUE),
third_quantile = quantile(Recommended_Customer_Price, 0.75, na.rm = TRUE),
maximum = max(Recommended_Customer_Price, na.rm = TRUE)
)
View(nF_summ)
# Creat color for diagram
my_palette <- colorRampPalette(c("blue", "yellow"))(20)
# Draw diagram
ggplot(newcpu_df, aes(x = Product_Collection, y = Recommended_Customer_Price, fill = Product_Collection)) +
geom_col() +
labs(title = 'Revenue of Products', x = 'Product', y = 'Total Price') +
theme_minimal() +
scale_fill_manual(values = my_palette) +
theme(axis.text.x = element_text()) +
scale_y_continuous(labels = scales::comma_format())
# Boxplot diagram about Product and Frequency Processor
# Summary
nF_summ <- newcpu_df %>%
group_by(Product_Collection) %>%
summarize(
sample_size = n(),
mean = mean(Processor_Base_Frequency, na.rm = TRUE),
sd = sd(Processor_Base_Frequency, na.rm = TRUE),
minimum = min(Processor_Base_Frequency, na.rm = TRUE),
first_quantile = quantile(Processor_Base_Frequency, 0.25, na.rm = TRUE),
median = median(Processor_Base_Frequency, na.rm = TRUE),
third_quantile = quantile(Processor_Base_Frequency, 0.75, na.rm = TRUE),
maximum = max(Processor_Base_Frequency, na.rm = TRUE)
)
View(nF_summ)
load("C:/Users/LAM TUAN HUY/OneDrive/Wordspace/xstk/btl/archive/.RData")
# Load the library for data manipulation
library(tidyr)
library(ggplot2)
library(dplyr)
# Read the Intel CPU dataset from a CSV file into a data frame
cpu_df <- read.csv("Intel_CPUs.csv", na.strings = c("", "N/A"))
# Create a new data frame containing only the columns of interest
newcpu_df <- cpu_df[, c("Product_Collection","Vertical_Segment","Launch_Date","Recommended_Customer_Price","nb_of_Cores","nb_of_Threads","Processor_Base_Frequency","Cache","Max_Memory_Size","Max_Memory_Bandwidth")]
# ----------------------------------------------------------------
product_category <- c('Legacy', 'Celeron', 'Pentium', 'Quark', 'Atom', 'Itanium', 'Xeon', 'Core')
for (i in product_category) {
newcpu_df$Product_Collection <- ifelse(grepl(i, newcpu_df$Product_Collection), i, newcpu_df$Product_Collection)
}
# Function to convert Launch_Date into "Year" format
convert_launch_date <- function(date_str) {
if (is.na(date_str)) {
return (NA)
}
year <- as.integer(substr(date_str, nchar(date_str) - 1, nchar(date_str)))
# Determine the century of the launch year
if (year > 17) {
year <- year + 1900
} else {
year <- year + 2000
}
# Return the launch year
launch_date_new <- year
return(launch_date_new)
}
# Apply the conversion function to Launch_Date
newcpu_df$Launch_Date <- sapply(newcpu_df$Launch_Date, convert_launch_date)
# Function to convert Processor_Base_Frequency to MHz
convert_freq_to_MHz <- function(freq) {
ifelse(grepl("GHz", freq), as.numeric(gsub("GHz", "", freq)) * 1000, as.numeric(gsub("MHz", "", freq)))
}
# Apply the conversion function to Processor_Base_Frequency
newcpu_df$Processor_Base_Frequency <- sapply(newcpu_df$Processor_Base_Frequency, convert_freq_to_MHz)
# Function to convert Price features from string to numeric
convert_price_to_num <- function(val) {
if (is.na(val)) {
return (NA)
}
val <- gsub("\\$", "", val)
val <- gsub(",", "", val)
if (grepl("-", val)) {
range <- strsplit(val, "-")[[1]]
val <- ((as.double(range[1]) + as.double(range[2])) / 2)
} else {
val <- as.double(val)
}
return(val)
}
# Apply the conversion function to Recommended_Customer_Price
newcpu_df$Recommended_Customer_Price <- sapply(newcpu_df$Recommended_Customer_Price, convert_price_to_num)
# Split Cache column into Cache_Size and Cache_Category
newcpu_df = separate(newcpu_df, Cache, into = c("Cache_Size", "Cache_Category"), sep="B")
# Remove the Cache_Category column
newcpu_df = newcpu_df[, -which(names(newcpu_df) == "Cache_Category")]
# Function to convert Cache_Size features from string to numeric
convert_cache_size_to_num <- function(val) {
if (is.na(val)) return(NA)
if (grepl("M", val)) {
return(as.double(gsub("M", "", val)) * 1024)
} else {
return(as.double(gsub("K", "", val)))
}
}
# Apply the conversion function to Cache_Size
newcpu_df$Cache_Size <- sapply(newcpu_df$Cache_Size, convert_cache_size_to_num)
# Function to convert Max_Memory_Size features from string to numeric
convert_mem_size_to_num <- function(val) {
if (is.na(val)) return(NA)
if (grepl("T", val)) {
res <- (as.double(gsub("TB", "", val)) * 1024)
return(res)
} else {
res <- (as.double(gsub("GB", "", val)))
return(res)
}
}
# Apply the conversion function to Max_Memory_Size
newcpu_df$Max_Memory_Size <- sapply(newcpu_df$Max_Memory_Size, convert_mem_size_to_num)
# Function to convert Max_Memory_Bandwidth from string to numeric
convert_mem_bandwidth_to_num <- function(val) {
if (is.na(val)) return(NA)
if (grepl("G", val)) {
res <- (as.double(gsub("GB/s", "", val)))
return(res)
}
}
# Apply the conversion function to Max_Memory_Bandwidth
newcpu_df$Max_Memory_Bandwidth <- sapply(newcpu_df$Max_Memory_Bandwidth, convert_mem_bandwidth_to_num)
# Statistics on the quantity of missing data in variables
apply(is.na(newcpu_df), 2, sum)
# Statistics on the percentage of missing data in variables
apply(is.na(newcpu_df), 2, mean)
# Filter out rows with missing Processor_Base_Frequency values
newcpu_df <- newcpu_df[complete.cases(newcpu_df$Processor_Base_Frequency), ]
# Filter out rows with missing Cache_Size values
newcpu_df <- newcpu_df[complete.cases(newcpu_df$Cache_Size), ]
# Apply the function to replace missing values with the median for columns with NA ratio >= 5% only
target_columns <- c("Launch_Date", "Recommended_Customer_Price", "nb_of_Threads", "Max_Memory_Size", "Max_Memory_Bandwidth")
newcpu_df[target_columns] <- sapply(newcpu_df[target_columns], replace_na_with_median <- function(x) {
median_val = median(x, na.rm = TRUE)
x[is.na(x)] <- median_val
return (x)
})
# Convert the result back into a DataFrame
newcpu_df <- as.data.frame(newcpu_df)
# Statistics on the quantity of missing data in variables
apply(is.na(newcpu_df), 2, sum)
# Statistics on the percentage of missing data in variables
apply(is.na(newcpu_df), 2, mean)
View(newcpu_df)
# Descriptive statistics
summary(newcpu_df)
# Histogram Revenue of each product
# Summary
nF_summ <- newcpu_df %>%
group_by(Product_Collection) %>%
summarize(
sample_size = n(),
mean = mean(Recommended_Customer_Price, na.rm = TRUE),
sd = sd(Recommended_Customer_Price, na.rm = TRUE),
minimum = min(Recommended_Customer_Price, na.rm = TRUE),
first_quantile = quantile(Recommended_Customer_Price, 0.25, na.rm = TRUE),
median = median(Recommended_Customer_Price, na.rm = TRUE),
third_quantile = quantile(Recommended_Customer_Price, 0.75, na.rm = TRUE),
maximum = max(Recommended_Customer_Price, na.rm = TRUE)
)
View(nF_summ)
# Creat color for diagram
my_palette <- colorRampPalette(c("blue", "yellow"))(20)
# Draw diagram
ggplot(newcpu_df, aes(x = Product_Collection, y = Recommended_Customer_Price, fill = Product_Collection)) +
geom_col() +
labs(title = 'Revenue of Products', x = 'Product', y = 'Total Price') +
theme_minimal() +
scale_fill_manual(values = my_palette) +
theme(axis.text.x = element_text()) +
scale_y_continuous(labels = scales::comma_format())
# Boxplot diagram about Product and Frequency Processor
# Summary
nF_summ <- newcpu_df %>%
group_by(Product_Collection) %>%
summarize(
sample_size = n(),
mean = mean(Processor_Base_Frequency, na.rm = TRUE),
sd = sd(Processor_Base_Frequency, na.rm = TRUE),
minimum = min(Processor_Base_Frequency, na.rm = TRUE),
first_quantile = quantile(Processor_Base_Frequency, 0.25, na.rm = TRUE),
median = median(Processor_Base_Frequency, na.rm = TRUE),
third_quantile = quantile(Processor_Base_Frequency, 0.75, na.rm = TRUE),
maximum = max(Processor_Base_Frequency, na.rm = TRUE)
)
View(nF_summ)
# Draw
ggplot(newcpu_df, aes(x = Product_Collection, y = Processor_Base_Frequency)) +
geom_boxplot() +
stat_summary(fun.y = "mean", geom = "point", color = "red") +
labs(x = "Product", y = "Processor Frequency", title = "Boxplot diagram about Processor Frequency of Products") +
theme_minimal()
# Scatter diagarm
# Summary
nF_summ <- newcpu_df %>%
group_by(Product_Collection) %>%
summarize(
sample_size = n(),
mean = mean(Max_Memory_Bandwidth, na.rm = TRUE),
sd = sd(Max_Memory_Bandwidth, na.rm = TRUE),
minimum = min(Max_Memory_Bandwidth, na.rm = TRUE),
first_quantile = quantile(Max_Memory_Bandwidth, 0.25, na.rm = TRUE),
median = median(Max_Memory_Bandwidth, na.rm = TRUE),
third_quantile = quantile(Max_Memory_Bandwidth, 0.75, na.rm = TRUE),
maximum = max(Max_Memory_Bandwidth, na.rm = TRUE)
)
View(nF_summ)
# Correlation matrix
summary(newcpu_df)
load("C:/Users/LAM TUAN HUY/OneDrive/Wordspace/xstk/btl/archive/.RData")
# Load the library for data manipulation
library(tidyr)
library(ggplot2)
library(dplyr)
# Read the Intel CPU dataset from a CSV file into a data frame
cpu_df <- read.csv("Intel_CPUs.csv", na.strings = c("", "N/A"))
# Create a new data frame containing only the columns of interest
newcpu_df <- cpu_df[, c("Product_Collection","Vertical_Segment","Launch_Date","Recommended_Customer_Price","nb_of_Cores","nb_of_Threads","Processor_Base_Frequency","Cache","Max_Memory_Size","Max_Memory_Bandwidth")]
# ----------------------------------------------------------------
product_category <- c('Legacy', 'Celeron', 'Pentium', 'Quark', 'Atom', 'Itanium', 'Xeon', 'Core')
for (i in product_category) {
newcpu_df$Product_Collection <- ifelse(grepl(i, newcpu_df$Product_Collection), i, newcpu_df$Product_Collection)
}
# Function to convert Launch_Date into "Year" format
convert_launch_date <- function(date_str) {
if (is.na(date_str)) {
return (NA)
}
year <- as.integer(substr(date_str, nchar(date_str) - 1, nchar(date_str)))
# Determine the century of the launch year
if (year > 17) {
year <- year + 1900
} else {
year <- year + 2000
}
# Return the launch year
launch_date_new <- year
return(launch_date_new)
}
# Apply the conversion function to Launch_Date
newcpu_df$Launch_Date <- sapply(newcpu_df$Launch_Date, convert_launch_date)
# Function to convert Processor_Base_Frequency to MHz
convert_freq_to_MHz <- function(freq) {
ifelse(grepl("GHz", freq), as.numeric(gsub("GHz", "", freq)) * 1000, as.numeric(gsub("MHz", "", freq)))
}
# Apply the conversion function to Processor_Base_Frequency
newcpu_df$Processor_Base_Frequency <- sapply(newcpu_df$Processor_Base_Frequency, convert_freq_to_MHz)
# Function to convert Price features from string to numeric
convert_price_to_num <- function(val) {
if (is.na(val)) {
return (NA)
}
val <- gsub("\\$", "", val)
val <- gsub(",", "", val)
if (grepl("-", val)) {
range <- strsplit(val, "-")[[1]]
val <- ((as.double(range[1]) + as.double(range[2])) / 2)
} else {
val <- as.double(val)
}
return(val)
}
# Apply the conversion function to Recommended_Customer_Price
newcpu_df$Recommended_Customer_Price <- sapply(newcpu_df$Recommended_Customer_Price, convert_price_to_num)
# Split Cache column into Cache_Size and Cache_Category
newcpu_df = separate(newcpu_df, Cache, into = c("Cache_Size", "Cache_Category"), sep="B")
# Remove the Cache_Category column
newcpu_df = newcpu_df[, -which(names(newcpu_df) == "Cache_Category")]
# Function to convert Cache_Size features from string to numeric
convert_cache_size_to_num <- function(val) {
if (is.na(val)) return(NA)
if (grepl("M", val)) {
return(as.double(gsub("M", "", val)) * 1024)
} else {
return(as.double(gsub("K", "", val)))
}
}
# Apply the conversion function to Cache_Size
newcpu_df$Cache_Size <- sapply(newcpu_df$Cache_Size, convert_cache_size_to_num)
# Function to convert Max_Memory_Size features from string to numeric
convert_mem_size_to_num <- function(val) {
if (is.na(val)) return(NA)
if (grepl("T", val)) {
res <- (as.double(gsub("TB", "", val)) * 1024)
return(res)
} else {
res <- (as.double(gsub("GB", "", val)))
return(res)
}
}
# Apply the conversion function to Max_Memory_Size
newcpu_df$Max_Memory_Size <- sapply(newcpu_df$Max_Memory_Size, convert_mem_size_to_num)
# Function to convert Max_Memory_Bandwidth from string to numeric
convert_mem_bandwidth_to_num <- function(val) {
if (is.na(val)) return(NA)
if (grepl("G", val)) {
res <- (as.double(gsub("GB/s", "", val)))
return(res)
}
}
# Apply the conversion function to Max_Memory_Bandwidth
newcpu_df$Max_Memory_Bandwidth <- sapply(newcpu_df$Max_Memory_Bandwidth, convert_mem_bandwidth_to_num)
# Statistics on the quantity of missing data in variables
apply(is.na(newcpu_df), 2, sum)
# Statistics on the percentage of missing data in variables
apply(is.na(newcpu_df), 2, mean)
# Filter out rows with missing Processor_Base_Frequency values
newcpu_df <- newcpu_df[complete.cases(newcpu_df$Processor_Base_Frequency), ]
# Filter out rows with missing Cache_Size values
newcpu_df <- newcpu_df[complete.cases(newcpu_df$Cache_Size), ]
# Apply the function to replace missing values with the median for columns with NA ratio >= 5% only
target_columns <- c("Launch_Date", "Recommended_Customer_Price", "nb_of_Threads", "Max_Memory_Size", "Max_Memory_Bandwidth")
newcpu_df[target_columns] <- sapply(newcpu_df[target_columns], replace_na_with_median <- function(x) {
median_val = median(x, na.rm = TRUE)
x[is.na(x)] <- median_val
return (x)
})
# Convert the result back into a DataFrame
newcpu_df <- as.data.frame(newcpu_df)
# Statistics on the quantity of missing data in variables
apply(is.na(newcpu_df), 2, sum)
# Statistics on the percentage of missing data in variables
apply(is.na(newcpu_df), 2, mean)
View(newcpu_df)
# Histogram Revenue of each product
# Summary
nF_summ <- newcpu_df %>%
group_by(Product_Collection) %>%
summarize(
sample_size = n(),
mean = mean(Recommended_Customer_Price, na.rm = TRUE),
sd = sd(Recommended_Customer_Price, na.rm = TRUE),
minimum = min(Recommended_Customer_Price, na.rm = TRUE),
first_quantile = quantile(Recommended_Customer_Price, 0.25, na.rm = TRUE),
median = median(Recommended_Customer_Price, na.rm = TRUE),
third_quantile = quantile(Recommended_Customer_Price, 0.75, na.rm = TRUE),
maximum = max(Recommended_Customer_Price, na.rm = TRUE)
)
View(nF_summ)
# Creat color for diagram
my_palette <- colorRampPalette(c("blue", "yellow"))(20)
# Draw diagram
ggplot(newcpu_df, aes(x = Product_Collection, y = Recommended_Customer_Price, fill = Product_Collection)) +
geom_col() +
labs(title = 'Revenue of Products', x = 'Product', y = 'Total Price') +
theme_minimal() +
scale_fill_manual(values = my_palette) +
theme(axis.text.x = element_text()) +
scale_y_continuous(labels = scales::comma_format())
# Boxplot diagram about Product and Frequency Processor
# Summary
nF_summ <- newcpu_df %>%
group_by(Product_Collection) %>%
summarize(
sample_size = n(),
mean = mean(Processor_Base_Frequency, na.rm = TRUE),
sd = sd(Processor_Base_Frequency, na.rm = TRUE),
minimum = min(Processor_Base_Frequency, na.rm = TRUE),
first_quantile = quantile(Processor_Base_Frequency, 0.25, na.rm = TRUE),
median = median(Processor_Base_Frequency, na.rm = TRUE),
third_quantile = quantile(Processor_Base_Frequency, 0.75, na.rm = TRUE),
maximum = max(Processor_Base_Frequency, na.rm = TRUE)
)
View(nF_summ)
# Draw
ggplot(newcpu_df, aes(x = Product_Collection, y = Processor_Base_Frequency)) +
geom_boxplot() +
stat_summary(fun.y = "mean", geom = "point", color = "red") +
labs(x = "Product", y = "Processor Frequency", title = "Boxplot diagram about Processor Frequency of Products") +
theme_minimal()
# Scatter diagarm
# Summary
nF_summ <- newcpu_df %>%
group_by(Product_Collection) %>%
summarize(
sample_size = n(),
mean = mean(Max_Memory_Bandwidth, na.rm = TRUE),
sd = sd(Max_Memory_Bandwidth, na.rm = TRUE),
minimum = min(Max_Memory_Bandwidth, na.rm = TRUE),
first_quantile = quantile(Max_Memory_Bandwidth, 0.25, na.rm = TRUE),
median = median(Max_Memory_Bandwidth, na.rm = TRUE),
third_quantile = quantile(Max_Memory_Bandwidth, 0.75, na.rm = TRUE),
maximum = max(Max_Memory_Bandwidth, na.rm = TRUE)
)
View(nF_summ)
# Draw
ggplot(newcpu_df, aes(x = Launch_Date, y = Max_Memory_Bandwidth, fill = Product_Collection)) +
geom_point(aes(col = Product_Collection, size = Max_Memory_Size)) +
geom_smooth(method = "lm") +
labs(x = "Year", y = "Memory Bandwidth", title = "Scatter diagram about Memory Bandwidth over Years of Products") +
scale_y_continuous(limits = c(0, 150)) +
scale_x_continuous(limits = c(1998, 2020)) +
theme_minimal() +
guides(col = guide_legend(title = "Production"),
size = guide_legend(title = "Memory Size"),
fill = guide_legend(title = "Production"))
# Correlation matrix
summary(newcpu_df)
# Choose numberic column from dataframe newcpu_df
numeric_cols <- Filter(is.numeric, newcpu_df)
# calculate correlation
correlation_matrix <- cor(numeric_cols)
print(correlation_matrix)
# Draw a heatmap plot that displays the correlation matrix
correlation_matrix_melted <- melt(correlation_matrix)
ggplot(correlation_matrix_melted, aes(Var1,Var2, fill = value, label = round(value, 2))) +
geom_tile(color = "white") +
geom_text(color = "black") +
scale_fill_gradient2(low = "blue", high = "#000080", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Correlation") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 10, hjust = 1)) +
coord_fixed() +
scale_y_discrete(limits = rev(levels(correlation_matrix_melted$Var2)))
# Draw a heatmap plot that displays the correlation matrix
correlation_matrix_melted <- melt(correlation_matrix)
library(reshape2)
install(tidyr)
install.packages("tidyr")
install.packages("tidyr")
install.packages("tidyr")
install.packages("tidyr")
